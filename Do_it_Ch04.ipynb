{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Do-it Ch04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syeong1218/python/blob/master/Do_it_Ch04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp7y8ASRK2hi",
        "colab_type": "text"
      },
      "source": [
        "# 04 분류하는 뉴런을 만듭니다 - 이진 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czf6Tz9dK2h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-oxffKULN_I",
        "colab_type": "text"
      },
      "source": [
        "## 04-1 초기 인공지능 알고리즘과 로지스틱 회귀를 알아봅시다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOKDN3t53MJu",
        "colab_type": "text"
      },
      "source": [
        "로지스틱 회귀를 제대로 이해하려면 인공지능 알고리즘들의 발전과정을 살펴보면 됩니다. 그 첫번째 알고리즘은 **퍼셉트론**입니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQxH6qPo4IFj",
        "colab_type": "text"
      },
      "source": [
        "### * 퍼셉트론에 대해 알아봅니다\n",
        "1957년 코넬 항공 연구소의 프랑크 로젠블라트가 이진 분류 문제에서 최적의 가중치를 학습하는 퍼셉트론 알고니즘을 발표하였습니다.\n",
        "* 이진 분류 : 임의의 샘플 데이터를 True나 False로 구분하는 문제 \n",
        "\n",
        "  ex) 과일이라는 샘플 데이터에서 사과가 True이면 사과인지(True), 아닌지(False)를 판단하는 것\n",
        "\n",
        "**퍼셉트론의 전체 구조를 훑어봅시다**\n",
        "\n",
        "퍼셉트론은 직선 방정식을 사용하기 때문에 선형 회귀와 유사한 구조를 가지고 있습니다. 하지만 퍼셉트론은 마지막 단계에서 샘플을 이진 분류하기 위하여 계단함수를 사용합니다. 그리고 계단 함수를 통과한 값을 다시 가중치와 절편을 업데이트(학습)하는데 사용합니다. 이를 그림으로 나타내면 다음과 같습니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/1.jpg?raw=true)\n",
        "\n",
        "왼쪽의 큰 동그라미는 뉴런으로 입력 신호들을 받아 z를 만듭니다. \n",
        "\n",
        "$$w_{1}x_{1}+w_{2}x_{2}+b=z$$\n",
        "\n",
        "이 수식을 지금부터 **선형 함수**라고 부르겠습니다.\n",
        "\n",
        "계단 함수는 z가 0보다 크거나 같으면 1로, 0보다 작으면 -1로 분류합니다.\n",
        "$$y=\\left\\{\\begin{matrix}\n",
        "1  (z\\geq 0)\\\\ \n",
        "-1  (z<0)\n",
        "\\end{matrix}\\right.$$\n",
        "이 때 1을 양성 클래스, -1을 음성 클래스라고 부르면 위 함수를 그래프로 그리면 다음그림처럼 계단 모양이 됩니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/2.jpg?raw=true)\n",
        "\n",
        "쉽게 말해 퍼셉트론은 선형 함수를 통과한 값 z를 계단 함수로 보내 0보다 큰지, 작은지 검사하여 1과 -1로 분류하는 간단한 알고니즘입니다. 퍼셉트론은 계단 함수의 결과를 사용하여 가중치와 절편을 업데이트합니다. \n",
        "\n",
        "**지금부터 여러 개의 특성을 사용하겠습니다.**\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/3.jpg?raw=true)\n",
        "\n",
        "왼쪽 그림은 3장에서 본 특성이 1개짜리이고, 오른쪽 그림은 특성이 2개인 경우의 선형 함수 표기법입니다. 아래 첨자로 사용한 숫자는 n번째 특성의 가중치와 입력을 의미합니다. 따라서 특성이 n개인 선형 함수를 다음과 같이 표기할 수 있습니다.\n",
        "\n",
        "$$z=w_{1}x_{1}+w_{2}x_{2}+\\cdots+w_{n}x_{n} +b$$\n",
        "\n",
        "이식을 시그마기호를 사용하여 간단하게 표기합니다.\n",
        "$$z=b+\\sum_{i=1}^{n}w_{i}x_{i}$$\n",
        "퍼셉트론은 사이킷런 패키지에서 Perceptron이라는 이름으로 클래스를 제공합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCrJnUGOk_xn",
        "colab_type": "text"
      },
      "source": [
        "### * 아달린에 대해 알아봅니다\n",
        "퍼셉트론을 개선한 적응형 선형 뉴런을 아달린이라고 부릅니다. 아달린은 선형 함수의 결과를 학습에 사용하고, 계단 함수의 결과는 예측에만 활용합니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/4.jpg?raw=true)\n",
        "\n",
        "역방향 계산이 계단 함수 출력 이후에 일어나지 않고 선형 함수 출력 이후에 진행됩니다. **로지스틱 회귀는 아달린의 개선 버전입니다**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Leoazqms5l",
        "colab_type": "text"
      },
      "source": [
        "### * 로지스틱 회귀에 대해 알아봅니다\n",
        "로지스틱 회귀는 아달린에서 조금 더 발전한 형태를 취하고 있습니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/5.jpg?raw=true)\n",
        "\n",
        "로지스틱 회귀는 선형 함수를 통과시켜 얻은 z를 임계 함수에 보내기 전에 변형시키는데, 이 함수를 활성화 함수라고 부릅니다. 활성화 함수를 통과한 값이 a로 표현되어 있는데 앞으로 a를 활성화 함수를 통과한 값이라고 이해하면 됩니다. 로지스틱 회귀는 마지막 단계에서 임계 함수를 사용하여 예측을 수행합니다. 임계 함수는 아달린이나 퍼셉트론의 계단 함수와 역할은 비슷하지만 활성화 함수의 출력값을 사용한다는 점이 다릅니다. \n",
        "\n",
        "**활성화 함수는 비선형 함수를 사용합니다**\n",
        "\n",
        "만약 활성화 함수가 선형 함수라면 어떻게 될까요? 선형 함수 $a=w_{1}x_{1}+w_{2}x_{2}+\\cdots+w_{n}x_{n}$과 활성화 함수 $y=ka$가 있다고 하고 결합하면 다음과 같습니다.\n",
        "$$y=k(w_{1}x_{1}+w_{2}x_{2}+\\cdots+w_{n}x_{n})$$\n",
        "두 식을 정리하면 다시 하나의 큰 선형 함수가 되기 때문에 임계 함수 앞에 뉴런을 여러 개 쌓아도 결국 선형 함수가 되므로 별 의미가 없습니다. 그래서 활성화 함수는 의무적으로 비선형 함수를 사용합니다. 다음은 비선형 함수의 한 예입니다.\n",
        "$$p=\\frac{1}{1+e^{-z}}$$\n",
        "**로지스틱 회귀의 활성화 함수는 시그모이드 함수입니다**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrWS-gI3K2iR",
        "colab_type": "text"
      },
      "source": [
        "## 04-2 시그모이드 함수를 알아봅니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdmOj60epMFZ",
        "colab_type": "text"
      },
      "source": [
        "### * 시그모이드 함수의 역할을 알아봅니다\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/6.jpg?raw=true)\n",
        "\n",
        "가장 왼쪽에 있는 뉴런이 선형 함수이고 출력값 $z=b+\\sum_{i=1}^{n}w_{i}x_{i}$입니다.\n",
        "\n",
        "출력값 z는 활성화 함수를 통과하여 a가 됩니다. 이 때 로지스틱 회귀에서 사용하는 활성화 함수인 시그모이드 함수는 z를 0~1사이의 확률값으로 변환시켜주는 역할을 합니다. 예를 들어 a를 암 종양 판정에 사용하면, 보통 a가 0.5보다 크면 양성 클래스, 그 이하면 음성 클래스라고 구분합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-tpHVRhqVuS",
        "colab_type": "text"
      },
      "source": [
        "### * 시그모이드 함수가 만들어지는 과정을 살펴봅니다\n",
        "\n",
        "시그모이드 함수는 다음과 같은 과정으로 만들어집니다.\n",
        "```\n",
        "오즈 비 -> 로짓 함수 -> 시그모이드 함수\n",
        "```\n",
        "**오즈 비에 대해 알아볼까요?**\n",
        "\n",
        "오즈 비는 성공 확률과 실패 확률의 비율을 나타내는 통계입니다.\n",
        "$$OR(odds ratio)=\\frac{p}{1-p}$$\n",
        "p=성공확률\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVkcpWZfK2iY",
        "colab_type": "code",
        "outputId": "099b6b63-5744-410d-e7fc-5995cf94d003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "probs = np.arange(0, 1, 0.01)\n",
        "odds = [p/(1-p) for p in probs]\n",
        "plt.plot(probs, odds)\n",
        "plt.xlabel('p')\n",
        "plt.ylabel('p/(1-p)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXQaSWZCrJY0",
        "colab_type": "text"
      },
      "source": [
        "p가 0부터 1까지 증가할 때 오즈 비의 값은 처음에는 천천히 증가하지만 p가 1에 가까워지면 급격히 증가합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw1tUOOZrN9e",
        "colab_type": "text"
      },
      "source": [
        "**로짓 함수에 대해 알아볼까요?**\n",
        "\n",
        "오즈 비에 로그 함수를 취하여 만든 함수를 로짓 함수라고 합니다.\n",
        "$$logit(p)=log(\\frac{p}{1-p})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyZrfyTqK2i1",
        "colab_type": "code",
        "outputId": "7e29d215-a10e-4d83-8f63-be890672e28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "probs  = np.arange(0.001, 0.999, 0.001)\n",
        "logit = [np.log(p/(1-p)) for p in probs]\n",
        "plt.plot(probs, logit)\n",
        "plt.xlabel('p')\n",
        "plt.ylabel('log(p/(1-p))')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4EzdysWremG",
        "colab_type": "text"
      },
      "source": [
        "로짓 함수는 p가 0.5일 때 0이 되고 p가 0과 1일때 각각 무한 음수와 양수가 됩니다. 로짓 함수의 세로 축을 z로, 가로 축을 p로 놓으면 확률 p가 0에서 1까지 변할 때 z가 매우 큰 음수에서 매우 큰 양수까지 변하는 것으로 볼 수 있습니다. 따라서 다음과 같은 식을 쓸 수 있습니다.\n",
        "$$log(\\frac{p}{1-p})=z$$\n",
        "\n",
        "**로지스틱 함수에 대해 알아볼까요?**\n",
        "\n",
        "그래프에서 z를 가로 축에 놓기 위해 위의 식을 z에 대하여 정리합니다.\n",
        "$$p=\\frac{1}{1+e^{-z}}$$\n",
        "로지스틱 함수를 그래프로 그려보면 로짓 함수의 가로와 세로 축을 반대로 뒤집어 높은 모양이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "gSiAkSjKK2jG",
        "colab_type": "code",
        "outputId": "93f64397-4fa8-458e-8c18-03c648dbfee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "zs = np.arange(-10., 10., 0.1)\n",
        "gs = [1/(1+np.exp(-z)) for z in zs]\n",
        "plt.plot(zs, gs)\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('1/(1+e^-z)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqIcbJpksftP",
        "colab_type": "text"
      },
      "source": [
        "S자 모양에서 착안하여 로지스틱 함수를 시그모이드 함수라고도 부릅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SPp1tsbso1O",
        "colab_type": "text"
      },
      "source": [
        "### * 로지스틱 회귀 중간 정리하기\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/7.jpg?raw=true)\n",
        "\n",
        "로지스틱 회귀는 이진 분류가 목표이므로 시그모이드 함수를 사용하여 $-\\infty$부터 $\\infty$의 범위를 가지는 z의 값을 조절합니다. 이는 시그모이드 함수를 통과하면 z를 확률처럼 해석할 수 있기 때문입니다. 그리고 시그모이드 함수의 확률인 a를 0과 1로 구분하기 위하여 마지막에 임계함수를 사용했습니다. 그 결과 입력 데이터(x)는 0 또는 1의 값으로 나누어져 이진 분류가 되었습니다. **따라서 로지스틱 회귀는 이진 분류를 하기 위한 알고리즘입니다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TZmauObubFX",
        "colab_type": "text"
      },
      "source": [
        "## 04-3 로지스틱 손실 함수를 경사 하강법에 적용합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoyzbPZMug5v",
        "colab_type": "text"
      },
      "source": [
        "선형 회귀는 정답과 예상값의 오차 제곱이 최소가 되는 가중치와 절편을 찾는 것이 목표였습니다. \n",
        "로지스틱 회귀의 목표는 올바르게 분류된 샘플 데이터의 비율 자체를 높이는 것입니다.\n",
        "\n",
        "예를 들면 사과, 배, 감을 분류하는 문제에서 사과, 배, 감으로 분류한 과일 중 진짜 사과, 배, 감으로 분류한 비율을 높이는 것이 분류의 목표입니다.\n",
        "\n",
        "올바르게 분류된 샘플의 비율은 미분 가능한 함수가 아니기 때문에 경사 하강법의 손실 함수를 사용할 수 없고 **로지스틱 손실 함수**을 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGaASUguv-_l",
        "colab_type": "text"
      },
      "source": [
        "### * 로지스틱 손실 함수를 제대로 알아봅시다\n",
        "\n",
        "로지스틱 손실 함수는 다중 분류를 위한 손실 함수인 크로스 엔트로피 손실 함수를 이진 분류 버전으로 만든 것입니다. 크로스 엔트로피 손실 함수는 7장에서 다중 분류를 다룰 때 자세히 나오므로 여기서는 그냥 크로스 엔트로피 손실 함수를 이용하여 로지스틱 손실 함수를 만들었다 정도만 알아두면 됩니다. 로지스틱 손실 함수는 다음과 같습니다.\n",
        "$$L=-(ylog(a)+(1-y)log(1-a))$$\n",
        "a는 활성화 함수가 출력한 값이고 y는 타깃입니다.\n",
        "\n",
        "이지 분류는 그렇다(1), 아니다(0)로, 타깃의 값은 1 또는 0입니다.\n",
        "\n",
        "|-|L|\n",
        "|:--------:|:--------:|\n",
        "|y가 1인 경우(양성 클래스)| -log(a)|\n",
        "|y가 0인 경우(음성 클래스)| -log(1-a)|\n",
        "\n",
        "앞 두 식의 값을 최소로 만들다 보면 a의 값이 우리가 원하는 목표치가 된다는 것을 알 수 있습니다. 예를 들어 양성 클래스인 경우 로지스틱 손실 함수의 값을 최소로 만들려면 a는 1에 가까워집니다. 반대로 음성 클래스인 경우 로지스틱 손실 함수의 값을 최소로 만들면 a가 0에 가까워집니다. 즉, 로지스틱 손실 함수를 최소화하면 a의 값이 우리가 가장 이상적으로 생각하는 값이 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H59upbMg10wE",
        "colab_type": "text"
      },
      "source": [
        "### * 로지스틱 손실 함수 미분하기\n",
        "가중치와 절편에 대한 로지스틱 손실 함수의 미분 결과는 다음과 같습니다.\n",
        "\n",
        "$$\\frac{\\partial }{\\partial w_{i}}L=1(y-a)x_{i}$$\n",
        "$$\\frac{\\partial }{\\partial b}L=1(y-a)1$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_CcGnOJ3txN",
        "colab_type": "text"
      },
      "source": [
        "|-|제곱 오차의 미분|로지스틱 손실 함수의 미분|\n",
        "|:--------:|:--------:|:--------:|\n",
        "|가중치에 대한 미분| $\\frac{\\partial SE}{\\partial w}=1(y-\\hat{y})x$|$\\frac{\\partial }{\\partial w_{i}}L=1(y-a)x_{i}$|\n",
        "|절편에 대한 미분| $\\frac{\\partial SE}{\\partial b}=1(y-\\hat{y})1$|$\\frac{\\partial }{\\partial b}L=1(y-a)1$|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTTGVvXb4co3",
        "colab_type": "text"
      },
      "source": [
        "제곱 오차의 미분과 로지스틱 손실 함수의 미분을 비교해보면 $\\hat{y}$가 a로 바뀌었을 뿐 결과는 동일하다. 즉, 로지스틱 회귀의 구현이 3장에서 만든 Neuron 클래스와 크게 다르지 않습니다. 따라서 **로지스틱 손실 함수의 미분을 통해 로지스틱 손실 함수의 값을 최소로 하는 가중치와 절편을 찾아야 한다는 점이 중요합니다**\n",
        "\n",
        "**로지스틱 손실 함수와 연쇄 법칙**\n",
        "\n",
        "합성 함수의 도함수를 구하기 위해 연쇄 법칙을 사용합니다.\n",
        "연쇄법칙을 간단하게 설명하면 $y=f(u), u=g(x)$라면, $\\frac{\\partial y}{\\partial x}=\\frac{\\partial y}{\\partial u}\\frac{\\partial u}{\\partial x}$이다.\n",
        "\n",
        "로지스틱 손실 함수 (L)를 가중치(w)나 절편(b)에 대하여 바로 미분하면 너무 복잡하기 때문에 연쇄 법칙을 사용합니다.\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/8.jpg?raw=true)\n",
        "\n",
        "그림을 보면 L를 a에 대하여 미분하고, a는 z에 대하여 미분하고, z는 w나 b에 대하여 미분한 다음 서로 곱하면 로지스틱 손실 함수를 가중치에 대하여 미분한 결과를 얻을 수 있습니다. 이 과정은 오른쪽부터 왼쪽까지 역방향으로 진행됩니다.\n",
        "$$\\frac{\\partial L}{\\partial w_{i}}=\\frac{\\partial L}{\\partial a}\\frac{\\partial a}{\\partial z}\\frac{\\partial z}{\\partial w_{i}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6XKYmgn8aPu",
        "colab_type": "text"
      },
      "source": [
        "**로지스틱 손실 함수를 a에 대하여 미분하기**\n",
        "\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial a}=\\frac{\\partial }{\\partial a}(-(ylog(a)+(1-y)log(1-a)=-(y\\frac{\\partial }{\\partial a}log(a)+(1-y)\\frac{\\partial }{\\partial a}log(1-a)$$\n",
        "간단하게 정리하면\n",
        "$$\\frac{\\partial L }{\\partial a}=-(y\\frac{1}{a}-(1-y)\\frac{1}{1-a})$$\n",
        "\n",
        "**a를 z에 대하여 미분하기**\n",
        "\n",
        "a는 시그모이드 함수로 z로 표현하면 $\\frac{1}{1+e^{-z}}$입니다.\n",
        "$$\\frac{\\partial a}{\\partial z}=\\frac{\\partial }{\\partial z}(\\frac{1}{1+e^{-z}})=\\frac{\\partial }{\\partial z}(1+e^{-z})^{-1}=-(1+e^{-z})^{-2}\\frac{\\partial }{\\partial z}(e^{-z})=-(1+e^{-z})^{-2}(e^{-z})=\\frac{e^{-z}}{(1+e^{-z})^{-2}}$$\n",
        "마지막 식을 정리하면 다음과 같습니다.\n",
        "$$\\frac{\\partial a}{\\partial z}=\\frac{1}{1+e^{-z}}\\frac{e^{-z}}{1+e^{-z}}=\\frac{1}{1+e^{-z}}(1-\\frac{1}{1+e^{-z}})=a(1-a)$$\n",
        "$$\\frac{\\partial a}{\\partial z}=a(1-a)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovb80ebt_UyD",
        "colab_type": "text"
      },
      "source": [
        "**z를 w에 대하여 미분하기**\n",
        "\n",
        "z는 선형 함수이므로 $w_{i}$로 미분하면 다음과 같습니다.\n",
        "$$\\frac{\\partial z}{\\partial w_{i}}=x_{i}$$\n",
        "\n",
        "**로지스틱 손실 함수를 w에 대하여 미분하기**\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w_{i}}=\\frac{\\partial L}{\\partial a}\\frac{\\partial a}{\\partial z}\\frac{\\partial z}{\\partial w_{i}}=-(y\\frac{1}{a}-(1-y)\\frac{1}{1-a})a(1-a)x_{i}=-(y(1-a)-(1-y)a)x_{i}=-(y-ya-a+ya)x_{i}=-(y-a)x_{i}$$\n",
        "로지스틱 손실 함수를 $w_{i}$에 대해 미분한 결과는 제곱 오차를 미분한 결과와 일치합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udwYizBJBWdP",
        "colab_type": "text"
      },
      "source": [
        "### * 로지스틱 손실 함수의 미분 과정 정리하고 역전파 이해하기\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/9.jpg?raw=true)\n",
        "\n",
        "오른쪽부터 살펴보면 L은 a에 대하여 미분하고, a는 z에 대하여 미분하고, z는 w에 대하여 미분합니다. 그리고 각 도함수의 곱은 가중치 업데이트에 사용합니다. 이렇게 로지스틱 손실 함수에 대한 미분이 연쇄 법칙에 의해 진행되는 구조를 **그레이디언트가 역전파된다**라고 합니다.\n",
        "\n",
        "**가중치 업데이트 방법 정리하기**\n",
        "\n",
        "로지스틱 손실 함수를 가중치에 대해 미분한 식을 가중치에서 빼면 됩니다.\n",
        "$$w_{i}=w_{i}-\\frac{\\partial L}{\\partial w_{i}}=w_{i}+(y-a)x_{i}$$\n",
        "\n",
        "**절편 업데이트 방법 정리하기**\n",
        "\n",
        "연쇄 법칙을 적용하면 쉽게 구할 수 있습니다. \n",
        "\n",
        "$$\\frac{\\partial L}{\\partial b}=\\frac{\\partial L}{\\partial z}\\frac{\\partial z}{\\partial b}=-(y-a)\\frac{\\partial }{\\partial b}(b+\\sum_{i=1}^{n}w_{i}x_{i})=-(y-a)1$$\n",
        "\n",
        "절편 업데이트 역시 로지스틱 손실 함수를 절편에 대해 미분한 식을 절편에서 빼면 됩니다.\n",
        "$$b=b-\\frac{\\partial L}{\\partial b}=b+(y-a)1$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY8hzKABK2jU",
        "colab_type": "text"
      },
      "source": [
        "## 04-4 분류용 데이터셋을 준비합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vqyGdvAEE_Q",
        "colab_type": "text"
      },
      "source": [
        "데이터 세트는 사이킷런에 포함된 위스콘신 유방암 데이터 세트를 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04zLJfKZEOT7",
        "colab_type": "text"
      },
      "source": [
        "### * 유방암 데이터 세트를 소개합니다\n",
        "유방암 데이터 세트에는 유방암 세포의 특징 10개에 대하여 평균, 표준 오차, 최대 이상치가 기록되어 있습니다. 여기서는 유방암 데이터 샘플이 악성 종양(True)인지, 정상 종양(False)인지를 구분하는 이진 분류를 수행합니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/10.jpg?raw=true)\n",
        "\n",
        "여기서 좋은 것을 음성 샘플, 나쁜 것을 양성 샘플이라 합니다. 따라서 해결해야하는 과제는 양성 샘플입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuZNtBsGFMhX",
        "colab_type": "text"
      },
      "source": [
        "### * 유방암 데이터 세트 준비하기\n",
        "**1. load_breast_cancer()함수 호출하기**\n",
        "\n",
        "사이킷런에서 위스콘신 유방암 데이터 세트를 불러옵니다. 사이킷런의 datasets 모듈 아래에 있는 load_breast_cancer()함수를 호출합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX2PmNBWK2jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUFVoY42F5nL",
        "colab_type": "text"
      },
      "source": [
        "**2. 입력 데이터 확인하기**\n",
        "\n",
        "입력 데이터인 cancer의 크기를 알아봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_1UUBCUK2jm",
        "colab_type": "code",
        "outputId": "aedc7a62-6ed0-4f3a-b1ae-41bce46bd891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(cancer.data.shape, cancer.target.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30) (569,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rGZ2kwiGHWo",
        "colab_type": "text"
      },
      "source": [
        "cancer에는 569개의 샘플과 30개의 특성이 있습니다. 이 중에서 처음 3개의 샘플을 출력해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T6YFWRNrK2j4",
        "colab_type": "code",
        "outputId": "02e9d73d-616c-4b5d-d71f-8553ba0853a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "cancer.data[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
              "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
              "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
              "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
              "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
              "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
              "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
              "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
              "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
              "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
              "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
              "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
              "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCdAke00GUsM",
        "colab_type": "text"
      },
      "source": [
        "특성 데이터를 살펴보면 실수 범위의 값이고 양수와 음수가 섞여 있습니다. 대괄호 1쌍으로 묶은 것이 1개의 샘플입니다. 특성이 30개이기 때문에 산점도가 아닌 박스 플롯을 이용하여 각 특성의 값을 나타내 보겠습니다.\n",
        "\n",
        "**3. 박스 플롯으로 특성의 사분위 관찰하기**\n",
        "\n",
        "박스 플롯은 1사분위와 3사분위 값으로 상자를 그린 다음 그 안에 2사분위(중간값)값을 표시합니다. 그런 다음 1사분위와 3사분위 사이 거리의 1.5배만큼 위아래 거리에서 각각 가장 큰 값과 가장 작은 값까지 수염을 그립니다. 박스 플롯을 사용하는 이유는 많은 데이터를 눈으로 확인하기 어려울 때 그림을 이용해 데이터 집합의 범위와 중앙값을 빠르게 확인할 수 있는 목적으로 사용합니다. 또한 통계적으로 이상치가 있는지도 확인이 가능힙니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/11.jpg?raw=true)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR39qDO4K2kH",
        "colab_type": "code",
        "outputId": "df7a3336-c640-487b-cf6f-7bf8693899c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.boxplot(cancer.data)\n",
        "plt.xlabel('feature')\n",
        "plt.ylabel('value')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEAaaORtH6B3",
        "colab_type": "text"
      },
      "source": [
        "**4. 눈에 띄는 특성 살펴보기**\n",
        "\n",
        "4, 14, 24번째 특성이 다른 특성보다 값의 분포가 휠씬 크다는 것을 알 수 있습니다. 각 특성을 확인해 보면,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL4VPt5uK2kY",
        "colab_type": "code",
        "outputId": "09a5df0e-b2ed-4fe3-a658-4b53400a6c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cancer.feature_names[[3,13,23]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean area', 'area error', 'worst area'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TahkXQEIZ7h",
        "colab_type": "text"
      },
      "source": [
        "모두 넓이와 관련된 특성임을 알 수 있습니다.\n",
        "\n",
        "\n",
        "**5. 타깃 데이터 확인하기**\n",
        "\n",
        "cancer.target 배열 안에는 0(음성 클래스)과 1(양성 클래스)만 들어 있습니다. 넘파이의 unique()함수를 사용하면 고유한 값을 찾아 반환합니다. 이 때 return_counts 매개변수를 True로 지정하면 고유한 값이 등장하는 횟수까지 세어 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi9WqcveK2kp",
        "colab_type": "code",
        "outputId": "39a88fde-b9a0-4500-af55-b1d4768ddf43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(cancer.target, return_counts=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([212, 357]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVjzDcKOJBhq",
        "colab_type": "text"
      },
      "source": [
        "왼쪽의 값 (array([0,1]))은 cancer.target에 들어 있는 고유한 값(0,1)을 의미합니다. \n",
        "\n",
        "오른쪽 값 (array([212,357]))은 타깃 데이터의 고유한 값의 개수를 센 다음 반환한 것입니다. 즉, 타깃 데이터에는 212개의 음성 클래스와 357개의 양성 클래스가 들어 있습니다.\n",
        "\n",
        "**6. 훈련 데이터 세트 저장하기**\n",
        "\n",
        "데이터 세트를 x, y 변수에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDmYOjoFK2k7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = cancer.data\n",
        "y = cancer.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgFTauvZK2lM",
        "colab_type": "text"
      },
      "source": [
        "## 04-5 로지스틱 회귀로 모델을 만들어봅니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za-jWMXXVmzJ",
        "colab_type": "text"
      },
      "source": [
        "3장에서 훈련 데이터 세트 전체를 사용하여 모델을 훈련했습니다. 그러나 모델의 성능을 평가하지 않았고 따라서 모델이 맞는지 아닌지를 알수가 없습니다. 여기서는 모델의 성능을 평가하는 방법에 대해서 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJXMfQP5V0KG",
        "colab_type": "text"
      },
      "source": [
        "### *모델의 성능 평가를 위한 훈련 세트와 테스트 세트 \n",
        "훈련된 모델의 실전 성능을 일반화 성능(generalization performance)이라고 부릅니다. 그런데 모델에 학습시킨 훈련 데이터 세트로 다시 모델의 성능을 평가하면 그 모델은 당연히 좋은 성능이 나올 것입니다. 이런 성능 평가를 '과도하게 낙관적으로 일반화 성능을 추정한다'고 말합니다. 따라서 훈련 데이터 세트를 두 덩어리로 나누어 하나는 훈련에, 다른 하나는 테스트에 사용하면 됩니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/12.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7atmQ-ESVpe7",
        "colab_type": "text"
      },
      "source": [
        "### * 훈련 세트와 테스트 세트로 나누기\n",
        "* 훈련 데이터 세트를 나눌 때는 테스트 \n",
        "세트보다 훈련 세트가 더 많아야 합니다.  \n",
        "* 훈련 데이터 세트를 나눌 때는 양성, 음성 클래스가 훈련 세트와 테스트 세트에 고르게 분포하도록 만들어야 합니다.\n",
        "\n",
        "만약 훈련 세트에 양성 클래스가 많이 몰리거나 테스트 세트에 음성 클래스가 너무 많이 몰리면 모델이 데이터에 있는 패턴을 올바르게 학습하지 못하거나 성능을 잘못 측정할 수도 있습니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/13.jpg?raw=true)\n",
        "\n",
        "위 그림을 보면 위쪽의 경우에는 그대로 2대1로 나누어져 잘 나누어졌고 밑쪽의 경우에는 클래스 비율이 망가져 있습니다. 클래스의 비율이 망가지면 모델에 사용할 데이터가 올바르지 않으므로 결과도 좋지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrrUJ0U-WRVI",
        "colab_type": "text"
      },
      "source": [
        "**1. train_test_split() 함수로 훈련 데이터 세트 나누기**\n",
        "\n",
        "사이킷런의 train_test_split() 함수는 기본적으로 입력된 훈련 데이터 세트를 훈련 세트 75%,테스트 세트 25% 비율로 나눠줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ct6eJajK2lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split # sklearn.model_selection 모듈에서 train_test_split()함수를 임포트"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Erss4IK2lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, \n",
        "                                                    test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-MZGEx8Wf7o",
        "colab_type": "text"
      },
      "source": [
        "* stratify는 훈련 데이터를 나눌 때 클래스 비율을 동일하게 만듭니다.\n",
        "* test_size는 기본적인 훈련 데이터 세트를 나누는 비율을 조절하고 싶을 때 사용합니다. 여기서는 test_size에 0.2를 전달하여 입력된 데이터 세트의 20%를 테스트 세트로 나눴습니다.\n",
        "* 무작위로 섞은 결과를 항상 일정하도록 하기 위해서 random_state에 난수 초깃값을 지정했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHcMxJZNWjEn",
        "colab_type": "text"
      },
      "source": [
        "**2. 결과 확인하기**\n",
        "\n",
        "이제 훈련 데이터 세트가 잘 나누어졌는지 훈련 세트와 테스트 세트의 비율을 확인해 보겠습니다. shape속성을 이용해 확인해 보면 훈련 세트와 테스트 세트가 4:1의 비율로 잘 나누어진 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOUKhJmMK2mB",
        "colab_type": "code",
        "outputId": "a5567b71-9240-4490-c6d0-aa799294539e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 30) (114, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZZfrT6UWnNR",
        "colab_type": "text"
      },
      "source": [
        "**3. unique() 함수로 훈련 세트의 타깃 확인하기**\n",
        "\n",
        "넘파이의 unique() 함수로 훈련 세트의 타깃안에 있는 클래스의 개수를 확인해 보면 전체 훈련 데이터 세트의 클래스 비율과 거의 비슷한 구성인것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tgES7zbK2mb",
        "colab_type": "code",
        "outputId": "fe33223f-c1a2-4f3e-acbf-30aa939201bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(y_train, return_counts=True) # y의 요소를 중복없이 알려주며 return_counts를 통해서 각각의 요소의 수를 알 수 있습니다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([170, 285]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdcrqElZWtub",
        "colab_type": "text"
      },
      "source": [
        "### 로지스틱 회귀 구현하기\n",
        "준비된 훈련 세트를 바탕으로 로지스틱 회귀를 구현해 보겠습니다. 로지스틱 회귀를 정방향으로 데이터가 흘러가는 과정(정방향 계산)부터 가중치를 업데이트하기 위해 역방향으로 데이터가 흘러가는 과정(역방향 계산)까지 순서대로 구현해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX-84wDnW0mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticNeuron:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z = np.sum(x * self.w) + self.b  # 직선 방정식을 계산합니다\n",
        "        return z\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err    # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va-A4jPJW2bx",
        "colab_type": "text"
      },
      "source": [
        "보면 3장에서 구현했던 Neuron클래스와는 다소 차이점이 있습니다. \n",
        "* 입력 데이터의 특성이 많아 `__init__()` 메서드는 가중치와 절편을 미리 초기화 하지 않습니다. 나중에 입력 데이터를 보고 특성 개수에 맞게 결정합니다.\n",
        "* forpass() 메서드를 보면 가중치와 입력 특성의 곱을 모두 더하기 위해 np.sum()함수를 사용한 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsdPBX8PK2m3",
        "colab_type": "code",
        "outputId": "5d79dd58-eff6-413f-c7f9-473553431866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([3,4,5])\n",
        "print(a + b)\n",
        "print(a * b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 6 8]\n",
            "[ 3  8 15]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPvLjcR2Ykp8",
        "colab_type": "text"
      },
      "source": [
        "넘파이 배열을 np.sum() 함수의 인자로 전달하면 각 요소를 모두 더한 값을 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3caV8QNK2ni",
        "colab_type": "code",
        "outputId": "d0e7a461-52b8-4b0f-a120-c7c294ee8712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.sum(a * b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YiQCgiFXS7J",
        "colab_type": "text"
      },
      "source": [
        "### 훈련하는 메서드 구현하기\n",
        "**1. fit() 메서드 구현하기**\n",
        "\n",
        "훈련을 수행하는 fit() 메서드를 구현해 보겠습니다. 기본 구조는 3장의 Neuron클래스와 같지만 활성화 함수가 추가되었고 역방향 계산에는 로지스틱 손실 함수의 도함수를 적용합니다. 앞에서 초기화하지 않은 가중치는 np.ones() 함수를 이용하여 간단히 1로 초기화하고 절편은 0으로 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrVU7NKPXZG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(self, x, y, epochs=100):\n",
        "    self.w = np.ones(x.shape[1])      # 가중치를 초기화합니다.\n",
        "    self.b = 0                        # 절편을 초기화합니다.\n",
        "    for i in range(epochs):           # epochs만큼 반복합니다\n",
        "        for x_i, y_i in zip(x, y):    # 모든 샘플에 대해 반복합니다 , zip을 이용해서 자료를 묶어줍니다.\n",
        "            z = self.forpass(x_i)     # 정방향 계산\n",
        "            a = self.activation(z)    # 활성화 함수 적용\n",
        "            err = -(y_i - a)          # 오차 계산\n",
        "            w_grad, b_grad = self.backprop(x_i, err) # 역방향 계산\n",
        "            self.w -= w_grad          # 가중치 업데이트\n",
        "            self.b -= b_grad          # 절편 업데이트"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kggvZ8CqjBcn",
        "colab_type": "text"
      },
      "source": [
        "잠시 넘파이에서 배열을 만들 때 특정 값으로 채우는 몇가지 함수를 보겠습니다. np.zeros() 함수는 배열의 요소를 전부 0으로 채웁니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ18hb1LK2oK",
        "colab_type": "code",
        "outputId": "6d713fbd-d5c1-40e7-fc6e-2e5c33b936a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "np.zeros((2, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTQ3U4TIlhjT",
        "colab_type": "text"
      },
      "source": [
        "0과 1이 아닌 임의의 값으로 배열을 생성하고 싶을 때는 np.full() 함수를 사용해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrRsxvjwK2ou",
        "colab_type": "code",
        "outputId": "afcde64e-ca97-4d1c-eaa8-7fc1b380eb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "np.full((2,3), 7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 7, 7],\n",
              "       [7, 7, 7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4XuMER6Xbh_",
        "colab_type": "text"
      },
      "source": [
        "**2. activation() 메서드 구현하기**\n",
        "\n",
        "시그모이드 함수가 사용되어야 합니다. 시그모이드 함수는 넘파이의 np.exp() 함수를 사용하여 간단히 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU34CMeqXf4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(self, z):\n",
        "    a = 1 / (1 + np.exp(-z))  # 시그모이드 계산\n",
        "    return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7RALqErXq5g",
        "colab_type": "text"
      },
      "source": [
        "### 예측하는 메서드 구현하기\n",
        "3장에서는 forpass() 메서드를 사용하여 새로운 샘플에 대한 예측값을 계산했으나 여러개의 샘플을 한꺼번에 예측할 때는 여러 번 호출해야하는 번거로움이 있습니다. 또한 분류에서는 활성화 함수와 임계 함수도 적용해야 하므로 새롭게 predict() 메서드를 만들어보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_QMR4OzXulD",
        "colab_type": "text"
      },
      "source": [
        "**1. predict() 메서드 구현하기**\n",
        "\n",
        "predict() 메서드의 매개변수 값으로 입력값 x가 2차원 배열로 전달된다고 가정하고 구현하게습니다. 예측값은 입력값을 선형 함수, 활성화 함수, 임계 함수 순서로 통과시키면 구할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXIBui-6Xx4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(self, x):\n",
        "    z = [self.forpass(x_i) for x_i in x]    # 정방향 계산\n",
        "    a = self.activation(np.array(z))        # 활성화 함수 적용\n",
        "    return a > 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H21QZn3-XzX6",
        "colab_type": "text"
      },
      "source": [
        "여기서 z의 계산에서 파이썬의 리스트 내포 문법을 사용했습니다. 리스트 내포란 대괄호([ ]) 안에 for문을 삽입하여 새 리스트를 만드는 문법입니다. x의 행을 하나씩 꺼내어 forpass() 메서드에 적용하고 그 결과를 이용하여 새 리스트(z)로 만드는 것입니다. z는 곧바로 넘파이 배열로 바꾸어 activation() 메서드로 전달됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBE2rgOoX2LV",
        "colab_type": "text"
      },
      "source": [
        "### 구현 내용 한눈에 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSzgJ4hSX5PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticNeuron:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z = np.sum(x * self.w) + self.b  # 직선 방정식을 계산합니다\n",
        "        return z\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err    # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def activation(self, z):\n",
        "        a = 1 / (1 + np.exp(-z))  # 시그모이드 계산\n",
        "        return a\n",
        "        \n",
        "    def fit(self, x, y, epochs=100):\n",
        "        self.w = np.ones(x.shape[1])      # 가중치를 초기화합니다.\n",
        "        self.b = 0                        # 절편을 초기화합니다.\n",
        "        for i in range(epochs):           # epochs만큼 반복합니다\n",
        "            for x_i, y_i in zip(x, y):    # 모든 샘플에 대해 반복합니다\n",
        "                z = self.forpass(x_i)     # 정방향 계산\n",
        "                a = self.activation(z)    # 활성화 함수 적용\n",
        "                err = -(y_i - a)          # 오차 계산\n",
        "                w_grad, b_grad = self.backprop(x_i, err) # 역방향 계산\n",
        "                self.w -= w_grad          # 가중치 업데이트\n",
        "                self.b -= b_grad          # 절편 업데이트\n",
        "    \n",
        "    def predict(self, x):\n",
        "        z = [self.forpass(x_i) for x_i in x]    # 정방향 계산\n",
        "        a = self.activation(np.array(z))        # 활성화 함수 적용\n",
        "        return a > 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sdV3jW0X76P",
        "colab_type": "text"
      },
      "source": [
        "### 로지스틱 회귀 모델 훈련시키기\n",
        "준비한 데이터 세트를 바탕으로 로지스틱 회귀 모델을 훈련하고 정확도를 측정하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoRnF1lOYAOS",
        "colab_type": "text"
      },
      "source": [
        "**1.모델 훈련하기**\n",
        "\n",
        "클래스의 객체를 만들고 훈련 세트와 함께 fit() 메서드를 호출하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydBUYQwNK2pL",
        "colab_type": "code",
        "outputId": "7ec460f9-ba05-46f5-ca86-3bc987bb83b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "neuron = LogisticNeuron()\n",
        "neuron.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovSZyPVMYEG-",
        "colab_type": "text"
      },
      "source": [
        "**2. 테스트 세트 사용해 모델의 정확도 평가하기**\n",
        "\n",
        "훈련이 끝난 모델에 테스트 세트를 사용해 예측값을 넣고 예측한 값이 맞는지 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOBnRmZvK2pc",
        "colab_type": "code",
        "outputId": "26adbe4f-c7f4-4c43-ce7e-c0de7f2c1ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "np.mean(neuron.predict(x_test) == y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8245614035087719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPnDl5cXYITS",
        "colab_type": "text"
      },
      "source": [
        "predict() 메서드의 반환값은 True나 False로 채워진 (m,) 크기의 배열이고 y_test는 0 또는 1로 채워진 (m,)크기의 배열이므로 바로 비교할 수 있습니다.np.mean() 함수는 매개변수 값으로 전달한 비교문 결과의 평균을 계산합니다. 즉, 계산 결과 0.82는 올바르게 예측한 샘플의 비율이 됩니다. 이를 정확도(accuracy)라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmBoMDokK2po",
        "colab_type": "text"
      },
      "source": [
        "## 04-6 단일층 신경망을 만들어 봅니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz09KW4SYLuf",
        "colab_type": "text"
      },
      "source": [
        "### 일반적인 신경망의 모습을 알아봅니다.\n",
        "일반적으로 신경망은 다음과 같이 표현합니다. 가장 왼쪽이 입력층(input layer), 가장 오른쪽이 출력층(output layer) 그리고 가운데 층들을 은닉층(hidden layer)이라고 부릅니다. 작은 원으로 표시된 활성화 함수는 각 층의 한 부분으로 간주합니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/14.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngBOsY_7YUMC",
        "colab_type": "text"
      },
      "source": [
        "**단일층 신경망의 모습을 알아봅니다**\n",
        "\n",
        "앞에서 배운 로지스틱 회귀는 은닉층이 없는 신경망이라고 볼 수 있습니다. 이런 입력층과 출력층만 가지는 신경망을 단일층 신경망이라고 부릅니다. 이거을 그림으로 나타내면 아래와 같습니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/15.jpg?raw=true)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNnp92aYYj9_",
        "colab_type": "text"
      },
      "source": [
        "### 단일층 신경망을 구현합니다\n",
        "\n",
        "여기서는 미리 구현한 LogisticNeuron 클래스에 몇 가지 유용한 기능을 추가하여 다시 구현해보겠습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNE-IjbpYnOB",
        "colab_type": "text"
      },
      "source": [
        "**손실 함수의 결괏값을 조정해 저장 기능 추가하기**\n",
        "\n",
        "`__init__()` 메서드에 손실 함수의 결괏값을 저장할 리스트 self.losses를 만듭니다.그런 다음 샘플마다 손실 함수를 계산하고 그 결괏값을 모두 더한 다음 샘플 개수로 나눈 평균값을 self.losses 변수에 저장합니다. 그리고 self.activation() 메서드로 계산한 a는 np.log()의 계산을 위해 한 번 더 조정합니다. 왜냐하면 a가 0에 가까워지면 np.log() 함수의 값은 음의 무한대가 되고 a가 1에 가까워지면 np.log() 함수의 값은 0이 되기 떄문입니다. 손실값이 무한해지면 계산을 할 수 없으므로 a의 값이 $1\\times 10^{-10}\\sim 1-1\\times 10^{-10}$ 사이가 되도록 np.clip() 함수로 조정해야 합니다. np.clip() 함수는 주어진 범위 밖의 값을 범위 양 끝의 값으로 잘라 냅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWqzKg2jYrPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __init__(self):\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "    self.losses = []\n",
        "\n",
        "def fit(self, x, y, epochs=100):\n",
        "        for i in index:                      # 모든 샘플에 대해 반복합니다\n",
        "            z = self.forpass(x[i])             # 정방향 계산\n",
        "            a = self.activation(z)             # 활성화 함수 적용\n",
        "            err = -(y[i] - a)                  # 오차 계산\n",
        "            w_grad, b_grad = self.backprop(x[i], err) # 역방향 계산\n",
        "            self.w -= w_grad                   # 가중치 업데이트\n",
        "            self.b -= b_grad                   # 절편 업데이트\n",
        "            # 안전한 로그 계산을 위해 클리핑한 후 손실을 누적합니다\n",
        "            a = np.clip(a, 1e-10, 1-1e-10)\n",
        "            loss += -(y[i]*np.log(a)+(1-y[i])*np.log(1-a)) # 에포크마다 평균 손실을 저장합니다\n",
        "        \n",
        "        self.losses.append(loss/len(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4PIZHE4YseQ",
        "colab_type": "text"
      },
      "source": [
        "### 여러 가지 경사 하강법에 대해 알아봅니다.\n",
        "지금까지 사용한 경사 하강법은 샘플 데이터 1개에 대한 그레디언트를 계산했습니다. 이를 확률적 경사 하강법(stochastic gradient descent)이라고 부릅니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/16.jpg?raw=true)\n",
        "\n",
        "또한 확률적 경사 하강법 외에 전체 훈련 세트를 사용하여 한 번에 그레디언트를 계산하는 방식인 배치 경사 하강법(batch gradient descent)과 배치(batch) 크기를 작게 하여(훈련 세트를 여러 번 나누어) 처리하는 방식인 미니 배치 경사 하강법(mini-batch gradient descent)이 있습니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/17.jpg?raw=true)\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/18.jpg?raw=true)\n",
        "\n",
        "확률적 경사 하강법은 샘플 데이터 1개마다 그레디언트를 계산하여 가중치를 업데이트하므로 계산 비용은 적은 대신 가중치가 최적값에 수렴하는 과정이 불안정합니다. 반면에 배치 경사 하강법은 전체 훈련 데이터 세트를 사용하여 한 번에 그레디언트를 계산하므로 가중치가 최적값에 수렴하는 과정은 안정적이지만 그만큼 계산 비용이 많이 듭니다. 이 둘의 장점을 절충한 것이 미니 배치 경사 하강법입니다. 다음은 확률적 경사 하강법, 배치 경사 하강법이 최적의 가중치(w1,w2)에 수렴하는 과정을 나타낸 그래프입니다. 미니 배치 경사 하강법은 확률적 경사 하강법보다는 매끄럽고 배치 경사 하강법보다는 덜 매끄러운 그래프가 그려집니다.\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/19.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3ul3u3UZP8E",
        "colab_type": "text"
      },
      "source": [
        "**매 에포크마다 훈련 세트의 샘플 순서를 섞어 사용하기**\n",
        "\n",
        "훈련 세트의 샘플 순서를 섞으면 가중치 최적값의 탐색 과정이 다양해져 가중치 최적값을 제대로 찾을 수 있습니다. 다음 그림은 첫 번째 에포크에서 사용한 샘플의 순서와 두 번째 에포크에서 사용한 샘플의 순서를 나타낸 것입니다.\n",
        "\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/20.jpg?raw=true)\n",
        "![대체 텍스트](https://github.com/syeong1218/python/blob/master/21.jpg?raw=true)\n",
        "\n",
        "훈련 세트의 샘플 순서를 섞는 전형적인 방법은 넘파이 배열의 인덱스를 섞은 후 인덱스 순서대로 샘플을 뽑는 것입니다. 이 방법이 훈련 세트 자체를 섞는 것보다 효율적이고 빠릅니다. np.random.permutation() 함수를 사용하면 이 방법을 구현할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jir9_X6ZdnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(self, x, y, epochs=100):\n",
        "    self.w = np.ones(x.shape[1])               # 가중치를 초기화합니다.\n",
        "    self.b = 0                                 # 절편을 초기화합니다.\n",
        "    for i in range(epochs):                    # epochs만큼 반복합니다\n",
        "        loss = 0\n",
        "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다\n",
        "        for i in indexes:                      # 모든 샘플에 대해 반복합니다\n",
        "            z = self.forpass(x[i])             # 정방향 계산\n",
        "            a = self.activation(z)             # 활성화 함수 적용\n",
        "            err = -(y[i] - a)                  # 오차 계산\n",
        "            w_grad, b_grad = self.backprop(x[i], err) # 역방향 계산\n",
        "            self.w -= w_grad                   # 가중치 업데이트\n",
        "            self.b -= b_grad                   # 절편 업데이트\n",
        "            a = np.clip(a, 1e-10, 1-1e-10)  # 안전한 로그 계산을 위해 클리핑한 후 손실을 누적합니다\n",
        "            loss += -(y[i]*np.log(a)+(1-y[i])*np.log(1-a))  # 에포크마다 평균 손실을 저장합니다\n",
        "        self.losses.append(loss/len(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RynidtgZfpN",
        "colab_type": "text"
      },
      "source": [
        "**score() 메서드 추가하기**\n",
        "\n",
        "정확도를 계산해 주는 score() 메서드를 추가하고 predict() 메서드도 수정하겠습니다. score() 메서드에는 정확도를 계산할 때 사용했던 np.mean() 함수를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpMZxvWdZi0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(self, x):\n",
        "    z = [self.forpass(x_i) for x_i in x]     # 정방향 계산\n",
        "    return np.array(z) > 0                   # 스텝 함수 적용\n",
        "    \n",
        "def score(self, x, y):\n",
        "    return np.mean(self.predict(x) == y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJFFne0QZj9H",
        "colab_type": "text"
      },
      "source": [
        "시그모이드 함수의 출력값은 0~1 사이의 확률값이고 양성 클래스를 판단하는 기준은 0.5이상입니다. 그런데 z가 0보다 크면 시그모이드 함수의 출력값은 0.5보다 크고 z가 0보다 작으면 시그모이드 함수의 출력값은 0.5보다 작습니다. 그래서 predict() 메서드에는 굳이 시그모이드 함수를 사용하지 않아도 됩니다. 그래서 predict() 메서드에는 로지스틱 함수를 적용하지 않고 z값의 크기만 비교하여 결과를 반환했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv7FWmN5K2pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SingleLayer:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.losses = []\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z = np.sum(x * self.w) + self.b  # 직선 방정식을 계산합니다\n",
        "        return z\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        w_grad = x * err    # 가중치에 대한 그래디언트를 계산합니다\n",
        "        b_grad = 1 * err    # 절편에 대한 그래디언트를 계산합니다\n",
        "        return w_grad, b_grad\n",
        "\n",
        "    def activation(self, z):\n",
        "        a = 1 / (1 + np.exp(-z))  # 시그모이드 계산\n",
        "        return a\n",
        "        \n",
        "    def fit(self, x, y, epochs=100):\n",
        "        self.w = np.ones(x.shape[1])               # 가중치를 초기화합니다.\n",
        "        self.b = 0                                 # 절편을 초기화합니다.\n",
        "        for i in range(epochs):                    # epochs만큼 반복합니다\n",
        "            loss = 0\n",
        "            # 인덱스를 섞습니다\n",
        "            indexes = np.random.permutation(np.arange(len(x)))\n",
        "            for i in indexes:                      # 모든 샘플에 대해 반복합니다\n",
        "                z = self.forpass(x[i])             # 정방향 계산\n",
        "                a = self.activation(z)             # 활성화 함수 적용\n",
        "                err = -(y[i] - a)                  # 오차 계산\n",
        "                w_grad, b_grad = self.backprop(x[i], err) # 역방향 계산\n",
        "                self.w -= w_grad                   # 가중치 업데이트\n",
        "                self.b -= b_grad                   # 절편 업데이트\n",
        "                a = np.clip(a, 1e-10, 1-1e-10) # 안전한 로그 계산을 위해 클리핑한 후 손실을 누적합니다\n",
        "                loss += -(y[i]*np.log(a)+(1-y[i])*np.log(1-a)) # 에포크마다 평균 손실을 저장합니다\n",
        "            \n",
        "            self.losses.append(loss/len(y))\n",
        "    \n",
        "    def predict(self, x):\n",
        "        z = [self.forpass(x_i) for x_i in x]     # 정방향 계산\n",
        "        return np.array(z) > 0                   # 스텝 함수 적용\n",
        "    \n",
        "    def score(self, x, y):\n",
        "        return np.mean(self.predict(x) == y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIhDutZZ08w",
        "colab_type": "text"
      },
      "source": [
        "### 단일층 신경망 훈련하기\n",
        "**1. 단일층 신경망 훈련하고 정확도 출력하기**\n",
        "\n",
        "클래스의 객체를 만들고 훈련 세트로 신경망을 훈련한 다음 score() 메서드로 정확도를 출력해겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STOFCy-mK2p4",
        "colab_type": "code",
        "outputId": "a4499ead-190c-4b1a-abac-945bcc73334d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "layer = SingleLayer()\n",
        "layer.fit(x_train, y_train)\n",
        "layer.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9298245614035088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlmnmb86Z5LI",
        "colab_type": "text"
      },
      "source": [
        "**2. 손실 함수 누적값 확인하기**\n",
        "\n",
        "성능이 에포크마다 훈련 세트를 무작위로 섞어 손실함수의 값을 줄였기 때문에 좋아졌습니다. 이를 확인하기 위해서 그래프를 그려보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TYyOsywMK2qH",
        "colab_type": "code",
        "outputId": "7223df31-000b-471c-d5e0-9dfe9731c4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.plot(layer.losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsdUCzTyNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1YFLQSmZ9dm",
        "colab_type": "text"
      },
      "source": [
        "로지스틱 손실 함수의 값이 에포크가 진행됨에 따라 감소하고 있음을 확인할 수 있습니다. 이로써 가장 기초적인 신경망 알고리즘이 구현되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2jn5nkXK2qW",
        "colab_type": "text"
      },
      "source": [
        "## 04-7 사이킷런의 경사 하강법을 사용해 봅니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40h_7clMZ_Kp",
        "colab_type": "text"
      },
      "source": [
        "사이킷런의 경사 하강법이 구현된 SGDClassifier클래스를 이용하여 로지스틱 회귀 문제를 간단히 해결해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tszSEHIYaBFS",
        "colab_type": "text"
      },
      "source": [
        "### 사이킷런으로 경사 하강법 적용하기\n",
        "**1. 로지스틱 손실 함수 지정하기**\n",
        "\n",
        "SGDClassifier 클래스에 로지스틱 회귀를 적용하려면 loss 매개변수에 손실 함수로 log를 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS_g6NWaK2qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cO5zT02aHst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGDClassifier(loss='log', max_iter=100, tol=1e-3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxokhGMgaI4d",
        "colab_type": "text"
      },
      "source": [
        "max_iter를 통해 반복 횟수를 100으로 지정합니다. 반복할 때마다 로지스틱 손실 함수의 값이 tol에 지정한 값만큼 감소되지 않으면 반복이 중단되도록 설정합니다. 만약 tol의 값을 설정하지 않으면 max_iter의 값을 늘리라는 경고가 발생합니다. 이는 모델의 로지스틱 손실 함수의 값이 최적값으로 수렴할 정도로 충분한 반복 횟수를 입력했는지 사용자에게 알려주므로 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sfCZKG6aLkX",
        "colab_type": "text"
      },
      "source": [
        "**2. 사이킷런으로 훈련하고 평가하기**\n",
        "\n",
        "사이킷런의 SGDClassifier 클래스에는 지금까지 우리가 직접 구현한 메서드가 이미 준비되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXJn4Bt_K2qs",
        "colab_type": "code",
        "outputId": "8dd61871-fd80-4b2d-bc4c-6cd9f744fdc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sgd.fit(x_train, y_train)\n",
        "sgd.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eThn-RvKaQPd",
        "colab_type": "text"
      },
      "source": [
        "**3. 사이킷런으로 예측하기**\n",
        "\n",
        "예측을 위한 메서드도 구현되었습니다. 주의할 점은 사이킷런은 입력 데이터로 2차원 배열만 받아들입니다.즉, 샘플 하나를 주입하더라도 2차원 배열로 만들어야 합니다. 여기서는 배열의 슬라이싱을 사용해 테스트 세트에서 10개의 샘플만 뽑아 예측을 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSjYGc2fK2rA",
        "colab_type": "code",
        "outputId": "66bf3c64-2dff-43a0-b014-7e752d6485a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sgd.predict(x_test[0:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ItcBeGT6sU",
        "colab_type": "code",
        "outputId": "953dbd85-40e9-4d0e-8835-dfa24553750f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}